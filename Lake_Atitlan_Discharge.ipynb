{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lake Atitlan Discharge.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN43AkGbXz4j0s+zWi/ZrMn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/almamyr/LakeAtitlan/blob/main/Lake_Atitlan_Discharge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lWTTOmTMrVf"
      },
      "source": [
        "# Install GEOGloWS package\n",
        "!pip install geoglows\n",
        "import geoglows\n",
        "from IPython.core.display import display, HTML\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzVDrqhuNKu3"
      },
      "source": [
        "# Import other packages\n",
        "from scipy import integrate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from datetime import timedelta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSSG4AkcM4EG"
      },
      "source": [
        "# Go collect the data for each river that flows into the lake\n",
        "reach_id_a = 951870\n",
        "stats_a = geoglows.streamflow.forecast_stats(reach_id_a)\n",
        "\n",
        "reach_id_b = 951853\n",
        "stats_b = geoglows.streamflow.forecast_stats(reach_id_b)\n",
        "\n",
        "reach_id_c = 951857\n",
        "stats_c = geoglows.streamflow.forecast_stats(reach_id_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leCRMIjdM7Hq"
      },
      "source": [
        "# Eliminate blank rows in the dataframe\n",
        "stats_a = stats_a[stats_a[\"flow_min_m^3/s\"].notna()]\n",
        "stats_b = stats_b[stats_b[\"flow_min_m^3/s\"].notna()]\n",
        "stats_c = stats_c[stats_c[\"flow_min_m^3/s\"].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8pzTb9LNEjo"
      },
      "source": [
        "# Convert to datetime\n",
        "stats_a.index = pd.to_datetime(stats_a.index)\n",
        "stats_b.index = pd.to_datetime(stats_b.index)\n",
        "stats_c.index = pd.to_datetime(stats_c.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBP4xu7ENGtg"
      },
      "source": [
        "# Get first timestep of each day\n",
        "midnight_a = stats_a[stats_a.index.hour == 0]\n",
        "midnight_b = stats_b[stats_b.index.hour == 0]\n",
        "midnight_c = stats_c[stats_c.index.hour == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9RTMGlCNPuu"
      },
      "source": [
        "# Create a dataset for each day of each dataframe\n",
        "\n",
        "for i in range (1,16):\n",
        "  locals()[\"day\"+str(i)+\"_a\"] = stats_a[stats_a.index.dayofyear == pd.to_datetime('today').dayofyear+(i-2)]\n",
        "  locals()[\"day\"+str(i)+\"_b\"] = stats_b[stats_b.index.dayofyear == pd.to_datetime('today').dayofyear+(i-2)]\n",
        "  locals()[\"day\"+str(i)+\"_c\"] = stats_c[stats_c.index.dayofyear == pd.to_datetime('today').dayofyear+(i-2)]\n",
        "\n",
        "  # Add the first timestep of the following day to the previous day's dataset\n",
        "  locals()[\"day\"+str(i)+\"_a\"] = locals()[\"day\"+str(i)+\"_a\"].append(midnight_a[midnight_a.index.dayofyear == pd.to_datetime('today').dayofyear+(i-1)])\n",
        "  locals()[\"day\"+str(i)+\"_b\"] = locals()[\"day\"+str(i)+\"_b\"].append(midnight_b[midnight_b.index.dayofyear == pd.to_datetime('today').dayofyear+(i-1)])\n",
        "  locals()[\"day\"+str(i)+\"_c\"] = locals()[\"day\"+str(i)+\"_c\"].append(midnight_c[midnight_c.index.dayofyear == pd.to_datetime('today').dayofyear+(i-1)])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTQZ7VXaNZW3"
      },
      "source": [
        "## Integrate Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt_rArBVNfpt"
      },
      "source": [
        "### Minimum "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDJUEdYiNbFb"
      },
      "source": [
        "# Integrate minimum volumes over each day\n",
        "# Timestep for the first 5 days is 3 hours (10800s), after that 6 hours (21600s)\n",
        "\n",
        "for i in range (1,16):\n",
        "  if i<6:\n",
        "    locals()[\"min_day\"+str(i)+\"_a\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_a\"][\"flow_min_m^3/s\"], dx = 10800)\n",
        "    locals()[\"min_day\"+str(i)+\"_b\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_b\"][\"flow_min_m^3/s\"], dx = 10800)\n",
        "    locals()[\"min_day\"+str(i)+\"_c\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_c\"][\"flow_min_m^3/s\"], dx = 10800)\n",
        "  if i>=6:\n",
        "    locals()[\"min_day\"+str(i)+\"_a\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_a\"][\"flow_min_m^3/s\"], dx = 21600)\n",
        "    locals()[\"min_day\"+str(i)+\"_b\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_b\"][\"flow_min_m^3/s\"], dx = 21600)\n",
        "    locals()[\"min_day\"+str(i)+\"_c\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_c\"][\"flow_min_m^3/s\"], dx = 21600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvyms5stNjGq"
      },
      "source": [
        "# Create an array for each stream containing daily minimum values\n",
        "\n",
        "min_a_array = np.zeros(15)\n",
        "min_b_array = np.zeros(15)\n",
        "min_c_array = np.zeros(15)\n",
        "\n",
        "for i in range (1,16): \n",
        "  min_a_array[i-1] = locals()[\"min_day\"+str(i)+\"_a\"]\n",
        "  min_b_array[i-1] = locals()[\"min_day\"+str(i)+\"_b\"]\n",
        "  min_c_array[i-1] = locals()[\"min_day\"+str(i)+\"_c\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsbVx_uCNlvm"
      },
      "source": [
        "# Add the min arrays to get total daily minimum volume\n",
        "min_array = min_a_array + min_b_array + min_c_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9FxpfJuNu3C"
      },
      "source": [
        "### Maximum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg5EZJDdNyGm"
      },
      "source": [
        "# Integrate maximum values over each day\n",
        "# Timestep for the first 5 days is 3 hours (10800s), after that 6 hours (21600s)\n",
        "\n",
        "for i in range (1,16):\n",
        "  if i<6:\n",
        "    locals()[\"max_day\"+str(i)+\"_a\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_a\"][\"flow_max_m^3/s\"], dx = 10800)\n",
        "    locals()[\"max_day\"+str(i)+\"_b\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_b\"][\"flow_max_m^3/s\"], dx = 10800)\n",
        "    locals()[\"max_day\"+str(i)+\"_c\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_c\"][\"flow_max_m^3/s\"], dx = 10800)\n",
        "  if i>=6:\n",
        "    locals()[\"max_day\"+str(i)+\"_a\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_a\"][\"flow_max_m^3/s\"], dx = 21600)\n",
        "    locals()[\"max_day\"+str(i)+\"_b\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_b\"][\"flow_max_m^3/s\"], dx = 21600)\n",
        "    locals()[\"max_day\"+str(i)+\"_c\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_c\"][\"flow_max_m^3/s\"], dx = 21600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwgBARQTN2nO"
      },
      "source": [
        "# Create an array for each stream containing daily maximum values\n",
        "\n",
        "max_a_array = np.zeros(15)\n",
        "max_b_array = np.zeros(15)\n",
        "max_c_array = np.zeros(15)\n",
        "\n",
        "for i in range (1,16): \n",
        "  max_a_array[i-1] = locals()[\"max_day\"+str(i)+\"_a\"]\n",
        "  max_b_array[i-1] = locals()[\"max_day\"+str(i)+\"_b\"]\n",
        "  max_c_array[i-1] = locals()[\"max_day\"+str(i)+\"_c\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg0E-DC5N5eD"
      },
      "source": [
        "# Add the max arrays to get total daily maximum volume\n",
        "max_array = max_a_array + max_b_array + max_c_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGBs2v0DOAW6"
      },
      "source": [
        "### Average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ3F5W7gN77W"
      },
      "source": [
        "# Integrate average values over each day\n",
        "# Timestep for the first 5 days is 3 hours (10800s), after that 6 hours (21600s)\n",
        "\n",
        "for i in range (1,16):\n",
        "  if i<6:\n",
        "    locals()[\"avg_day\"+str(i)+\"_a\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_a\"][\"flow_avg_m^3/s\"], dx = 10800)\n",
        "    locals()[\"avg_day\"+str(i)+\"_b\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_b\"][\"flow_avg_m^3/s\"], dx = 10800)\n",
        "    locals()[\"avg_day\"+str(i)+\"_c\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_c\"][\"flow_avg_m^3/s\"], dx = 10800)\n",
        "  if i>=6:\n",
        "    locals()[\"avg_day\"+str(i)+\"_a\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_a\"][\"flow_avg_m^3/s\"], dx = 21600)\n",
        "    locals()[\"avg_day\"+str(i)+\"_b\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_b\"][\"flow_avg_m^3/s\"], dx = 21600)\n",
        "    locals()[\"avg_day\"+str(i)+\"_c\"] = integrate.trapz(y = locals()[\"day\"+str(i)+\"_c\"][\"flow_avg_m^3/s\"], dx = 21600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fviEN_uOG7m"
      },
      "source": [
        "# Create an array for each stream containing daily mean values\n",
        "\n",
        "avg_a_array = np.zeros(15)\n",
        "avg_b_array = np.zeros(15)\n",
        "avg_c_array = np.zeros(15)\n",
        "\n",
        "for i in range (1,16): \n",
        "  avg_a_array[i-1] = locals()[\"avg_day\"+str(i)+\"_a\"]\n",
        "  avg_b_array[i-1] = locals()[\"avg_day\"+str(i)+\"_b\"]\n",
        "  avg_c_array[i-1] = locals()[\"avg_day\"+str(i)+\"_c\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzpICjOEOKh8"
      },
      "source": [
        "# Add the avg arrays to get total daily average volume\n",
        "avg_array = avg_a_array + avg_b_array + avg_c_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA-V3EumQoLp"
      },
      "source": [
        "## Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RcTfVAvQkOU"
      },
      "source": [
        "print(\"Minimum:\", min_array)\n",
        "print(\"Maximum:\", max_array)\n",
        "print(\"Average:\", avg_array)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}